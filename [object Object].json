{"text":"I need to analyze this diff to understand what changes were made across the project.\n\nThe main changes appear to be:\n1. Replacing specific AI SDKs with the more general AI SDK from Vercel\n2. Removing lefthook (a git hooks manager)\n3. Updating the .gitignore to handle multiple outputs\n4. Updating dependencies in package.json\n5. Enhancing the README with more references and information\n6. Refactoring the API integration code to use the new SDK\n7. Simplifying the git diff retrieval with simple-git\n\nThe summary should capture the main theme of these changes. The most significant change is the switch from specific AI provider SDKs to the more general AI SDK framework, which enables support for multiple AI providers.\n\nLet me try a summary: \"refactor: switch to AI SDK for multi-provider support\"\n\nThis is fairly general and covers the main architectural change, but could be more specific about what providers are now supported.\n\nBetter summary: \"refactor: replace Anthropic/Groq SDKs with AI SDK for multi-provider support\"\n\nThis is more comprehensive and specific, mentioning both what was removed and what was added, while staying under 72 characters.\n\nrefactor: replace Anthropic/Groq SDKs with AI SDK for multi-provider support\n\nThe commit modernizes the project's AI integration by:\n- Replacing direct Anthropic and Groq SDKs with Vercel's AI SDK\n- Adding support for multiple AI providers (Anthropic, Deepseek, XAI)\n- Simplifying git operations with simple-git library\n- Removing lefthook git hooks manager\n- Updating .gitignore to handle multiple outputs directory\n- Enhancing README with additional references and documentation\n- Restructuring the prompt generation to work with the new SDK","reasoningDetails":[],"toolCalls":[],"toolResults":[],"finishReason":"stop","usage":{"promptTokens":5026,"completionTokens":410,"totalTokens":5436},"warnings":[],"request":{"body":"{\"model\":\"claude-3-7-sonnet-latest\",\"max_tokens\":1024,\"temperature\":0,\"system\":[{\"type\":\"text\",\"text\":\"You are a senior software engineer working as the lead of a popular open-source project. You are presented with a code diff, and must understand the changes, then write a proper commit message for them. You will be given an example to understand what the message should look like generally\"}],\"messages\":[{\"role\":\"user\",\"content\":[{\"type\":\"text\",\"text\":\"<diff>diff --git a/.gitignore b/.gitignore\\nindex 0010644..4fc382d 100644\\n--- a/.gitignore\\n+++ b/.gitignore\\n@@ -1,5 +1,5 @@\\n node_modules\\n .env\\n .vscode\\n-output.json\\n-diff.txt\\n\\\\ No newline at end of file\\n+diff.txt\\n+outputs\\n\\\\ No newline at end of file\\ndiff --git a/lefthook.yml b/lefthook.yml\\ndeleted file mode 100644\\nindex 3ac5730..0000000\\n--- a/lefthook.yml\\n+++ /dev/null\\n@@ -1,42 +0,0 @@\\n-# EXAMPLE USAGE:\\n-#\\n-#   Refer for explanation to following link:\\n-#   https://lefthook.dev/configuration/\\n-#\\n-# pre-push:\\n-#   jobs:\\n-#     - name: packages audit\\n-#       tags:\\n-#         - frontend\\n-#         - security\\n-#       run: yarn audit\\n-#\\n-#     - name: gems audit\\n-#       tags:\\n-#         - backend\\n-#         - security\\n-#       run: bundle audit\\n-#\\n-# pre-commit:\\n-#   parallel: true\\n-#   jobs:\\n-#     - run: yarn eslint {staged_files}\\n-#       glob: \\\"*.{js,ts,jsx,tsx}\\\"\\n-#\\n-#     - name: rubocop\\n-#       glob: \\\"*.rb\\\"\\n-#       exclude:\\n-#         - config/application.rb\\n-#         - config/routes.rb\\n-#       run: bundle exec rubocop --force-exclusion {all_files}\\n-#\\n-#     - name: govet\\n-#       files: git ls-files -m\\n-#       glob: \\\"*.go\\\"\\n-#       run: go vet {files}\\n-#\\n-#     - script: \\\"hello.js\\\"\\n-#       runner: node\\n-#\\n-#     - script: \\\"hello.go\\\"\\n-#       runner: go run\\ndiff --git a/package-lock.json b/package-lock.json\\nindex 4f2de61..d66d5c2 100644\\nBinary files a/package-lock.json and b/package-lock.json differ\\ndiff --git a/package.json b/package.json\\nindex 6cf176c..bb75b61 100644\\n--- a/package.json\\n+++ b/package.json\\n@@ -4,20 +4,23 @@\\n   \\\"description\\\": \\\"Turns diffs into concise, readable git commit messages\\\",\\n   \\\"author\\\": \\\"Conrad Kay\\\",\\n   \\\"homepage\\\": \\\"https://github.com/conradbkay/llm-commit\\\",\\n-  \\\"devDependencies\\\": {\\n-    \\\"lefthook\\\": \\\"^1.11.2\\\",\\n-    \\\"prettier\\\": \\\"^3.5.2\\\",\\n-    \\\"tsx\\\": \\\"^4.19.3\\\",\\n-    \\\"vitest\\\": \\\"^3.0.7\\\"\\n-  },\\n   \\\"scripts\\\": {\\n     \\\"start\\\": \\\"tsx --env-file=.env src/index.ts\\\",\\n     \\\"prepare\\\": \\\"husky\\\"\\n   },\\n   \\\"dependencies\\\": {\\n-    \\\"@anthropic-ai/sdk\\\": \\\"^0.37.0\\\",\\n+    \\\"@ai-sdk/anthropic\\\": \\\"^1.1.15\\\",\\n+    \\\"@ai-sdk/deepseek\\\": \\\"^0.1.13\\\",\\n+    \\\"@ai-sdk/xai\\\": \\\"^1.1.13\\\",\\n     \\\"@promptbook/utils\\\": \\\"^0.86.10\\\",\\n-    \\\"groq-sdk\\\": \\\"^0.15.0\\\",\\n-    \\\"repomix\\\": \\\"^0.2.30\\\"\\n+    \\\"ai\\\": \\\"^4.1.53\\\",\\n+    \\\"globby\\\": \\\"~14.0.2\\\",\\n+    \\\"repomix\\\": \\\"^0.2.30\\\",\\n+    \\\"simple-git\\\": \\\"^3.27.0\\\"\\n+  },\\n+  \\\"devDependencies\\\": {\\n+    \\\"prettier\\\": \\\"^3.5.2\\\",\\n+    \\\"tsx\\\": \\\"^4.19.3\\\",\\n+    \\\"vitest\\\": \\\"^3.0.7\\\"\\n   }\\n }\\ndiff --git a/readme.md b/readme.md\\nindex 7a1cb92..938afd7 100644\\n--- a/readme.md\\n+++ b/readme.md\\n@@ -2,15 +2,22 @@\\n \\n Hopefully use any model to generate above average commit messages. The bar has never been lower\\n \\n-Most of the refinement will likely come in the form of better prompting, or just better models being released\\n+<https://repomix.com/guide/> some ideas for giving code to LLMs\\n+\\n+<https://harper.blog/2024/03/11/use-an-llm-to-automagically-generate-meaningful-git-commit-messages/> basic idea\\n+\\n+<https://cbea.ms/git-commit/>\\n \\n ## Setup\\n \\n ### .env\\n \\n+Follows <https://sdk.vercel.ai/providers/ai-sdk-providers> defaults\\n+\\n ```ini\\n ANTHROPIC_API_KEY=\\n-GROQ_API_KEY=\\n+XAI_API_KEY=\\n+DEEPSEEK_API_KEY=\\n ```\\n \\n ### Beyond .gitignore\\n@@ -26,7 +33,6 @@ Client side can add `package-lock.json -diff` to `.gitattributes`\\n ## Roadmap\\n \\n - Turn into a CLI tool\\n-- More APIs (Deepseek, openAI)\\n - Benchmarking performance (obviously will be subjective comparison)\\n - Run on previous commits\\n - Run on commits in date range, manually approve/deny all changes or ask it to try again\\n@@ -39,6 +45,12 @@ Input tokens will likely be 10-100x output. Basic prompting with small commits w\\n - 625 commits/$ using 3.5 Haiku\\n - 167 commits/$ using 3.7 Sonnet\\n \\n+Maybe it'll handle doing several commits from one prompt well, which would reduce cost a lot if using a lot of general codebase context\\n+\\n ## Benchmarking\\n \\n+## Misc\\n+\\n Diff is ugly to present usually, maybe some react package for that\\n+\\n+Probably prefer diffs in plain format since training data might work with diffs, but could try out something like diff/parse-diff/parse-git-diff\\ndiff --git a/src/api/anthropic.ts b/src/api/anthropic.ts\\ndeleted file mode 100644\\nindex 756013e..0000000\\n--- a/src/api/anthropic.ts\\n+++ /dev/null\\n@@ -1,26 +0,0 @@\\n-import Anthropic from '@anthropic-ai/sdk'\\n-import {\\n-  MessageCreateParamsNonStreaming,\\n-  ThinkingConfigParam\\n-} from '@anthropic-ai/sdk/resources/index.mjs'\\n-\\n-const client = new Anthropic({\\n-  apiKey: process.env['ANTHROPIC_API_KEY'] // This is the default and can be omitted\\n-})\\n-\\n-export const { create } = client.messages\\n-\\n-export const configs: Record<\\n-  string,\\n-  (tokens?: number) => Partial<MessageCreateParamsNonStreaming> & {\\n-    model: string\\n-  }\\n-> = {\\n-  sonnet_think: (tokens: number = 1024) => ({\\n-    max_tokens: tokens * 2,\\n-    thinking: { type: 'enabled', budget_tokens: tokens } as ThinkingConfigParam,\\n-    model: 'claude-3-7-sonnet-latest'\\n-  }),\\n-  sonnet: () => ({ model: 'claude-3-7-sonnet-latest' }),\\n-  haiku: () => ({ model: 'claude3-5-haiku-latest' })\\n-}\\ndiff --git a/src/api/git.ts b/src/api/git.ts\\nindex 5d15fa6..5237b66 100644\\n--- a/src/api/git.ts\\n+++ b/src/api/git.ts\\n@@ -1,47 +1,9 @@\\n-// git diff HEAD~1 will show things like warnings and changes to .gitignore'd files\\n+import { simpleGit } from 'simple-git'\\n \\n-// git show HEAD~1 --numstat more machine readable\\n+export const getDiff = async () => {\\n+  const git = simpleGit()\\n \\n-// git diff HEAD~1 ':!package-lock.json' outputs\\n+  const diff = await git.diff()\\n \\n-/*\\n-diff --git a/package.json b/package.json\\n-index 500e658..ed3b56f 100644\\n---- a/package.json\\n-+++ b/package.json\\n-@@ -6,13 +6,15 @@\\n-   \\\"homepage\\\": \\\"https://github.com/conradbkay/llm-commit\\\",\\n-   \\\"devDependencies\\\": {\\n-     \\\"prettier\\\": \\\"^3.5.2\\\",\\n--    \\\"tsx\\\": \\\"^4.19.3\\\"\\n-+    \\\"tsx\\\": \\\"^4.19.3\\\",\\n-+    \\\"vitest\\\": \\\"^3.0.7\\\"\\n-   },\\n-   \\\"scripts\\\": {\\n-     \\\"start\\\": \\\"tsx --env-file=.env src/index.ts\\\"\\n-   },\\n-diff --git a/package.json b/package.json\\n-index 500e658..ed3b56f 100644\\n---- a/package.json\\n-+++ b/package.json\\n-@@ -6,13 +6,15 @@\\n-   \\\"homepage\\\": \\\"https://github.com/conradbkay/llm-commit\\\",\\n-   \\\"devDependencies\\\": {\\n-     \\\"prettier\\\": \\\"^3.5.2\\\",\\n--    \\\"tsx\\\": \\\"^4.19.3\\\"\\n-+    \\\"tsx\\\": \\\"^4.19.3\\\",\\n-+    \\\"vitest\\\": \\\"^3.0.7\\\"\\n-   },\\n-   \\\"scripts\\\": {\\n-     \\\"start\\\": \\\"tsx --env-file=.env src/index.ts\\\"\\n-   },\\n-   \\\"dependencies\\\": {\\n-     \\\"@anthropic-ai/sdk\\\": \\\"^0.37.0\\\",\\n--    \\\"groq-sdk\\\": \\\"^0.15.0\\\"\\n-+    \\\"groq-sdk\\\": \\\"^0.15.0\\\",\\n-+    \\\"repomix\\\": \\\"^0.2.30\\\"\\n-   }\\n- }\\n-diff --git a/prompting.md b/prompting.md\\n-index de0b3ad..61745aa 100644\\n-*/\\n+  return diff\\n+}\\ndiff --git a/src/api/groq.ts b/src/api/groq.ts\\ndeleted file mode 100644\\nindex adb6849..0000000\\n--- a/src/api/groq.ts\\n+++ /dev/null\\n@@ -1,7 +0,0 @@\\n-import Groq from 'groq-sdk'\\n-\\n-const client = new Groq({\\n-  apiKey: process.env['GROQ_API_KEY'] // This is the default and can be omitted\\n-})\\n-\\n-export const { create } = client.chat.completions\\ndiff --git a/src/index.ts b/src/index.ts\\nindex 07cfbdf..66f1d8a 100644\\n--- a/src/index.ts\\n+++ b/src/index.ts\\n@@ -1,35 +1,34 @@\\n import { writeFile } from 'fs/promises'\\n import { genPrompt } from './prompt'\\n import { unwrapResult } from '@promptbook/utils'\\n-import { configs, create } from './api/anthropic'\\n-import { readFileSync } from 'fs'\\n-import { resolve } from 'path'\\n-\\n-const diff = readFileSync(resolve('./diff.txt'), 'utf8')\\n+import { generateText } from 'ai'\\n+import { anthropic } from '@ai-sdk/anthropic'\\n+import { getDiff } from './api/git'\\n \\n const TOKENS = 1024\\n+const THINK_MODE = 'disabled'\\n \\n async function main() {\\n-  const message = await create({\\n-    max_tokens: TOKENS,\\n-    messages: [\\n-      {\\n-        role: 'user',\\n-        content: genPrompt(diff)\\n+  const model = anthropic('claude-3-7-sonnet-latest')\\n+\\n+  const diff = await getDiff()\\n+\\n+  const prompt = genPrompt(diff)\\n+\\n+  const message = await generateText({\\n+    model,\\n+    maxTokens: TOKENS,\\n+    ...prompt,\\n+    providerOptions: {\\n+      anthropic: {\\n+        thinking: { type: THINK_MODE, budgetTokens: Math.floor(TOKENS / 2) }\\n       }\\n-    ],\\n-    ...configs.sonnet_think(TOKENS)\\n+    }\\n   })\\n \\n-  if (message.content[message.content.length - 1].type !== 'text') {\\n-    throw new Error('Unexpected output length/type')\\n-  }\\n-\\n-  console.log(\\n-    unwrapResult((message.content[message.content.length - 1] as any).text)\\n-  )\\n+  console.log(unwrapResult(message.text))\\n \\n-  await writeFile('output.json', JSON.stringify(message), 'utf8')\\n+  await writeFile(model + '.json', JSON.stringify(message), 'utf8')\\n }\\n \\n main()\\ndiff --git a/src/prompt.ts b/src/prompt.ts\\nindex ca16c6f..684fa56 100644\\n--- a/src/prompt.ts\\n+++ b/src/prompt.ts\\n@@ -1,39 +1,48 @@\\n+const system =\\n+  'You are a senior software engineer working as the lead of a popular open-source project. You are presented with a code diff, and must understand the changes, then write a proper commit message for them. You will be given an example to understand what the message should look like generally'\\n+\\n // not all of these will be used. See baseDisable and custom based on model\\n const instructions = {\\n-  task: 'Your goal is to write a git commit message for a code diff',\\n-  senior:\\n-    'Reply as a senior software engineer who takes pride in their commit messages',\\n-  formatSummary:\\n-    'Always write a summary for the first line, which should be short, less than 72 characters and ideally less than 50 characters',\\n-  formatDesc:\\n-    'Any additional text is purely optional and should come after a blank line. Feel free to use bullet point format. Try not to reiterate every trivial change made to the code',\\n   logic:\\n-    \\\"Before outputting the commit, think for a few sentences about what the diffs mean, creating a list of changes. Make sure the summary generalizes to most of the changes and doesn't just focus on one. Try generating a summary, then saying whether it is general, comprehensive, and concise then trying to make a better one. Use that one in your final message rather than coming up with a separate summary\\\",\\n-  noIntro: 'Do NOT start with things like \\\"here is a commit message\\\"',\\n-  diffExplain:\\n-    'The text that follows is the code diff for the commit, your message should reflect these changes',\\n-  noHallucinate:\\n-    \\\"Be very careful not to describe any changes that weren't definitely made. It is much better to produce a very short message than make anything up\\\"\\n+    \\\"\\\\n\\\\nBefore outputting the commit, think for a few sentences about what the diffs mean, creating a list of changes. Make sure the summary generalizes to most of the changes and doesn't just focus on one. Try generating a summary, then saying whether it is general, comprehensive, and concise then trying to make a better one. Use that one in your final message rather than coming up with a separate summary. For each point, try referencing which file change(s) it correlates to\\\",\\n+  'no-hallicinate':\\n+    \\\"Be very careful not to describe any changes that weren't definitely made. It is much better to produce a very short message than make anything up\\\",\\n+  examples: `\\\\n\\\\n<example>\\n+updated code to use locally hosted ollama llm, nomic-embed-text model\\n+</example>\\n+  \\n+  <example>Update setup_mcp.py\\n+Added import platform to detect the operating system\\n+Used platform.system() to check if it's Windows or not\\n+Adjusted pip and python paths:\\n+\\n+Windows: uses 'Scripts' folder and '.exe' extension\\n+Mac/Linux: uses 'bin' folder without extension\\n+\\n+The script now automatically detects the operating system and uses the appropriate paths for each one, making it compatible with both Windows and macOS/Linux systems</example>\\n+\\n+<example>\\n+set the embedding model in an environment variable\\n+</example>`,\\n+  'think-first':\\n+    '\\\\n\\\\nPlease make sure your commit message comes after any thinking/reasoning about the code changes'\\n } as const\\n \\n-// mostly used for benchmarking/prompt development\\n+// used for benchmarking/prompt development\\n const experimentalInstructions = {\\n-  outputUsage:\\n+  'output-usage':\\n     'Your output will be fed to git commit -m \\\"[your commit message]\\\"',\\n   explanation: 'Explain why changes were made'\\n } as const\\n \\n const instructionKeyOrder = [\\n-  'task',\\n-  'senior',\\n   'explanation',\\n-  'outputUsage',\\n-  'formatSummary',\\n-  'formatDesc',\\n-  'logic',\\n-  'noIntro',\\n-  'diffExplain',\\n-  'noHallucinate'\\n+  'output-usage',\\n+  // just use a thinking model for this?\\n+  //'logic',\\n+  //'no-hallucinate',\\n+  'examples',\\n+  'think-first'\\n ] as const\\n \\n export const genPrompt = (\\n@@ -44,10 +53,20 @@ export const genPrompt = (\\n     .filter(\\n       (key) => key in instructions && !disableInstructionKeys.includes(key)\\n     )\\n-    .reduce((accum, instructionKey) => {\\n-      return accum + instructions[instructionKey] + '. '\\n-    }, '')\\n+    .map((key) => instructions[key])\\n+    .join('')\\n     .trim()\\n \\n-  return base + '\\\\n\\\\n' + diff\\n+  return {\\n+    system,\\n+    messages: [\\n+      // apparently long context (20k+) at the top performs a lot better, but can test for shorter\\n+      { role: 'user' as const, content: `<diff>${diff}</diff>\\\\n\\\\n${base}` }\\n+      // causes error for think mode\\n+      /*{\\n+        role: 'assistant' as const,\\n+        content: 'The first change to the code is'\\n+      }*/\\n+    ]\\n+  }\\n }\\n</diff>\\n\\n<example>\\nupdated code to use locally hosted ollama llm, nomic-embed-text model\\n</example>\\n  \\n  <example>Update setup_mcp.py\\nAdded import platform to detect the operating system\\nUsed platform.system() to check if it's Windows or not\\nAdjusted pip and python paths:\\n\\nWindows: uses 'Scripts' folder and '.exe' extension\\nMac/Linux: uses 'bin' folder without extension\\n\\nThe script now automatically detects the operating system and uses the appropriate paths for each one, making it compatible with both Windows and macOS/Linux systems</example>\\n\\n<example>\\nset the embedding model in an environment variable\\n</example>\\n\\nPlease make sure your commit message comes after any thinking/reasoning about the code changes\"}]}]}"},"response":{"id":"msg_01VFxH36ygfXHZTA5kYxz4At","timestamp":"2025-03-05T23:28:43.002Z","modelId":"claude-3-7-sonnet-20250219","headers":{"anthropic-organization-id":"08ef5215-d715-4f22-a8e0-171ce4bd7da4","anthropic-ratelimit-input-tokens-limit":"20000","anthropic-ratelimit-input-tokens-remaining":"15000","anthropic-ratelimit-input-tokens-reset":"2025-03-05T23:28:50Z","anthropic-ratelimit-output-tokens-limit":"8000","anthropic-ratelimit-output-tokens-remaining":"8000","anthropic-ratelimit-output-tokens-reset":"2025-03-05T23:28:44Z","anthropic-ratelimit-requests-limit":"50","anthropic-ratelimit-requests-remaining":"49","anthropic-ratelimit-requests-reset":"2025-03-05T23:28:36Z","anthropic-ratelimit-tokens-limit":"28000","anthropic-ratelimit-tokens-remaining":"23000","anthropic-ratelimit-tokens-reset":"2025-03-05T23:28:44Z","cf-cache-status":"DYNAMIC","cf-ray":"91bd63feddad3035-BOS","connection":"keep-alive","content-encoding":"gzip","content-type":"application/json","date":"Wed, 05 Mar 2025 23:28:44 GMT","request-id":"req_01Cp2xDev6FER5htHt32pJDr","server":"cloudflare","transfer-encoding":"chunked","via":"1.1 google","x-robots-tag":"none"},"body":{"id":"msg_01VFxH36ygfXHZTA5kYxz4At","type":"message","role":"assistant","model":"claude-3-7-sonnet-20250219","content":[{"type":"text","text":"I need to analyze this diff to understand what changes were made across the project.\n\nThe main changes appear to be:\n1. Replacing specific AI SDKs with the more general AI SDK from Vercel\n2. Removing lefthook (a git hooks manager)\n3. Updating the .gitignore to handle multiple outputs\n4. Updating dependencies in package.json\n5. Enhancing the README with more references and information\n6. Refactoring the API integration code to use the new SDK\n7. Simplifying the git diff retrieval with simple-git\n\nThe summary should capture the main theme of these changes. The most significant change is the switch from specific AI provider SDKs to the more general AI SDK framework, which enables support for multiple AI providers.\n\nLet me try a summary: \"refactor: switch to AI SDK for multi-provider support\"\n\nThis is fairly general and covers the main architectural change, but could be more specific about what providers are now supported.\n\nBetter summary: \"refactor: replace Anthropic/Groq SDKs with AI SDK for multi-provider support\"\n\nThis is more comprehensive and specific, mentioning both what was removed and what was added, while staying under 72 characters.\n\nrefactor: replace Anthropic/Groq SDKs with AI SDK for multi-provider support\n\nThe commit modernizes the project's AI integration by:\n- Replacing direct Anthropic and Groq SDKs with Vercel's AI SDK\n- Adding support for multiple AI providers (Anthropic, Deepseek, XAI)\n- Simplifying git operations with simple-git library\n- Removing lefthook git hooks manager\n- Updating .gitignore to handle multiple outputs directory\n- Enhancing README with additional references and documentation\n- Restructuring the prompt generation to work with the new SDK"}],"stop_reason":"end_turn","stop_sequence":null,"usage":{"input_tokens":5026,"cache_creation_input_tokens":0,"cache_read_input_tokens":0,"output_tokens":410}},"messages":[{"role":"assistant","content":[{"type":"text","text":"I need to analyze this diff to understand what changes were made across the project.\n\nThe main changes appear to be:\n1. Replacing specific AI SDKs with the more general AI SDK from Vercel\n2. Removing lefthook (a git hooks manager)\n3. Updating the .gitignore to handle multiple outputs\n4. Updating dependencies in package.json\n5. Enhancing the README with more references and information\n6. Refactoring the API integration code to use the new SDK\n7. Simplifying the git diff retrieval with simple-git\n\nThe summary should capture the main theme of these changes. The most significant change is the switch from specific AI provider SDKs to the more general AI SDK framework, which enables support for multiple AI providers.\n\nLet me try a summary: \"refactor: switch to AI SDK for multi-provider support\"\n\nThis is fairly general and covers the main architectural change, but could be more specific about what providers are now supported.\n\nBetter summary: \"refactor: replace Anthropic/Groq SDKs with AI SDK for multi-provider support\"\n\nThis is more comprehensive and specific, mentioning both what was removed and what was added, while staying under 72 characters.\n\nrefactor: replace Anthropic/Groq SDKs with AI SDK for multi-provider support\n\nThe commit modernizes the project's AI integration by:\n- Replacing direct Anthropic and Groq SDKs with Vercel's AI SDK\n- Adding support for multiple AI providers (Anthropic, Deepseek, XAI)\n- Simplifying git operations with simple-git library\n- Removing lefthook git hooks manager\n- Updating .gitignore to handle multiple outputs directory\n- Enhancing README with additional references and documentation\n- Restructuring the prompt generation to work with the new SDK"}],"id":"msg-IN4H4qAMY3NqkyJ2IyjcvEdC"}]},"steps":[{"stepType":"initial","text":"I need to analyze this diff to understand what changes were made across the project.\n\nThe main changes appear to be:\n1. Replacing specific AI SDKs with the more general AI SDK from Vercel\n2. Removing lefthook (a git hooks manager)\n3. Updating the .gitignore to handle multiple outputs\n4. Updating dependencies in package.json\n5. Enhancing the README with more references and information\n6. Refactoring the API integration code to use the new SDK\n7. Simplifying the git diff retrieval with simple-git\n\nThe summary should capture the main theme of these changes. The most significant change is the switch from specific AI provider SDKs to the more general AI SDK framework, which enables support for multiple AI providers.\n\nLet me try a summary: \"refactor: switch to AI SDK for multi-provider support\"\n\nThis is fairly general and covers the main architectural change, but could be more specific about what providers are now supported.\n\nBetter summary: \"refactor: replace Anthropic/Groq SDKs with AI SDK for multi-provider support\"\n\nThis is more comprehensive and specific, mentioning both what was removed and what was added, while staying under 72 characters.\n\nrefactor: replace Anthropic/Groq SDKs with AI SDK for multi-provider support\n\nThe commit modernizes the project's AI integration by:\n- Replacing direct Anthropic and Groq SDKs with Vercel's AI SDK\n- Adding support for multiple AI providers (Anthropic, Deepseek, XAI)\n- Simplifying git operations with simple-git library\n- Removing lefthook git hooks manager\n- Updating .gitignore to handle multiple outputs directory\n- Enhancing README with additional references and documentation\n- Restructuring the prompt generation to work with the new SDK","reasoningDetails":[],"sources":[],"toolCalls":[],"toolResults":[],"finishReason":"stop","usage":{"promptTokens":5026,"completionTokens":410,"totalTokens":5436},"warnings":[],"request":{"body":"{\"model\":\"claude-3-7-sonnet-latest\",\"max_tokens\":1024,\"temperature\":0,\"system\":[{\"type\":\"text\",\"text\":\"You are a senior software engineer working as the lead of a popular open-source project. You are presented with a code diff, and must understand the changes, then write a proper commit message for them. You will be given an example to understand what the message should look like generally\"}],\"messages\":[{\"role\":\"user\",\"content\":[{\"type\":\"text\",\"text\":\"<diff>diff --git a/.gitignore b/.gitignore\\nindex 0010644..4fc382d 100644\\n--- a/.gitignore\\n+++ b/.gitignore\\n@@ -1,5 +1,5 @@\\n node_modules\\n .env\\n .vscode\\n-output.json\\n-diff.txt\\n\\\\ No newline at end of file\\n+diff.txt\\n+outputs\\n\\\\ No newline at end of file\\ndiff --git a/lefthook.yml b/lefthook.yml\\ndeleted file mode 100644\\nindex 3ac5730..0000000\\n--- a/lefthook.yml\\n+++ /dev/null\\n@@ -1,42 +0,0 @@\\n-# EXAMPLE USAGE:\\n-#\\n-#   Refer for explanation to following link:\\n-#   https://lefthook.dev/configuration/\\n-#\\n-# pre-push:\\n-#   jobs:\\n-#     - name: packages audit\\n-#       tags:\\n-#         - frontend\\n-#         - security\\n-#       run: yarn audit\\n-#\\n-#     - name: gems audit\\n-#       tags:\\n-#         - backend\\n-#         - security\\n-#       run: bundle audit\\n-#\\n-# pre-commit:\\n-#   parallel: true\\n-#   jobs:\\n-#     - run: yarn eslint {staged_files}\\n-#       glob: \\\"*.{js,ts,jsx,tsx}\\\"\\n-#\\n-#     - name: rubocop\\n-#       glob: \\\"*.rb\\\"\\n-#       exclude:\\n-#         - config/application.rb\\n-#         - config/routes.rb\\n-#       run: bundle exec rubocop --force-exclusion {all_files}\\n-#\\n-#     - name: govet\\n-#       files: git ls-files -m\\n-#       glob: \\\"*.go\\\"\\n-#       run: go vet {files}\\n-#\\n-#     - script: \\\"hello.js\\\"\\n-#       runner: node\\n-#\\n-#     - script: \\\"hello.go\\\"\\n-#       runner: go run\\ndiff --git a/package-lock.json b/package-lock.json\\nindex 4f2de61..d66d5c2 100644\\nBinary files a/package-lock.json and b/package-lock.json differ\\ndiff --git a/package.json b/package.json\\nindex 6cf176c..bb75b61 100644\\n--- a/package.json\\n+++ b/package.json\\n@@ -4,20 +4,23 @@\\n   \\\"description\\\": \\\"Turns diffs into concise, readable git commit messages\\\",\\n   \\\"author\\\": \\\"Conrad Kay\\\",\\n   \\\"homepage\\\": \\\"https://github.com/conradbkay/llm-commit\\\",\\n-  \\\"devDependencies\\\": {\\n-    \\\"lefthook\\\": \\\"^1.11.2\\\",\\n-    \\\"prettier\\\": \\\"^3.5.2\\\",\\n-    \\\"tsx\\\": \\\"^4.19.3\\\",\\n-    \\\"vitest\\\": \\\"^3.0.7\\\"\\n-  },\\n   \\\"scripts\\\": {\\n     \\\"start\\\": \\\"tsx --env-file=.env src/index.ts\\\",\\n     \\\"prepare\\\": \\\"husky\\\"\\n   },\\n   \\\"dependencies\\\": {\\n-    \\\"@anthropic-ai/sdk\\\": \\\"^0.37.0\\\",\\n+    \\\"@ai-sdk/anthropic\\\": \\\"^1.1.15\\\",\\n+    \\\"@ai-sdk/deepseek\\\": \\\"^0.1.13\\\",\\n+    \\\"@ai-sdk/xai\\\": \\\"^1.1.13\\\",\\n     \\\"@promptbook/utils\\\": \\\"^0.86.10\\\",\\n-    \\\"groq-sdk\\\": \\\"^0.15.0\\\",\\n-    \\\"repomix\\\": \\\"^0.2.30\\\"\\n+    \\\"ai\\\": \\\"^4.1.53\\\",\\n+    \\\"globby\\\": \\\"~14.0.2\\\",\\n+    \\\"repomix\\\": \\\"^0.2.30\\\",\\n+    \\\"simple-git\\\": \\\"^3.27.0\\\"\\n+  },\\n+  \\\"devDependencies\\\": {\\n+    \\\"prettier\\\": \\\"^3.5.2\\\",\\n+    \\\"tsx\\\": \\\"^4.19.3\\\",\\n+    \\\"vitest\\\": \\\"^3.0.7\\\"\\n   }\\n }\\ndiff --git a/readme.md b/readme.md\\nindex 7a1cb92..938afd7 100644\\n--- a/readme.md\\n+++ b/readme.md\\n@@ -2,15 +2,22 @@\\n \\n Hopefully use any model to generate above average commit messages. The bar has never been lower\\n \\n-Most of the refinement will likely come in the form of better prompting, or just better models being released\\n+<https://repomix.com/guide/> some ideas for giving code to LLMs\\n+\\n+<https://harper.blog/2024/03/11/use-an-llm-to-automagically-generate-meaningful-git-commit-messages/> basic idea\\n+\\n+<https://cbea.ms/git-commit/>\\n \\n ## Setup\\n \\n ### .env\\n \\n+Follows <https://sdk.vercel.ai/providers/ai-sdk-providers> defaults\\n+\\n ```ini\\n ANTHROPIC_API_KEY=\\n-GROQ_API_KEY=\\n+XAI_API_KEY=\\n+DEEPSEEK_API_KEY=\\n ```\\n \\n ### Beyond .gitignore\\n@@ -26,7 +33,6 @@ Client side can add `package-lock.json -diff` to `.gitattributes`\\n ## Roadmap\\n \\n - Turn into a CLI tool\\n-- More APIs (Deepseek, openAI)\\n - Benchmarking performance (obviously will be subjective comparison)\\n - Run on previous commits\\n - Run on commits in date range, manually approve/deny all changes or ask it to try again\\n@@ -39,6 +45,12 @@ Input tokens will likely be 10-100x output. Basic prompting with small commits w\\n - 625 commits/$ using 3.5 Haiku\\n - 167 commits/$ using 3.7 Sonnet\\n \\n+Maybe it'll handle doing several commits from one prompt well, which would reduce cost a lot if using a lot of general codebase context\\n+\\n ## Benchmarking\\n \\n+## Misc\\n+\\n Diff is ugly to present usually, maybe some react package for that\\n+\\n+Probably prefer diffs in plain format since training data might work with diffs, but could try out something like diff/parse-diff/parse-git-diff\\ndiff --git a/src/api/anthropic.ts b/src/api/anthropic.ts\\ndeleted file mode 100644\\nindex 756013e..0000000\\n--- a/src/api/anthropic.ts\\n+++ /dev/null\\n@@ -1,26 +0,0 @@\\n-import Anthropic from '@anthropic-ai/sdk'\\n-import {\\n-  MessageCreateParamsNonStreaming,\\n-  ThinkingConfigParam\\n-} from '@anthropic-ai/sdk/resources/index.mjs'\\n-\\n-const client = new Anthropic({\\n-  apiKey: process.env['ANTHROPIC_API_KEY'] // This is the default and can be omitted\\n-})\\n-\\n-export const { create } = client.messages\\n-\\n-export const configs: Record<\\n-  string,\\n-  (tokens?: number) => Partial<MessageCreateParamsNonStreaming> & {\\n-    model: string\\n-  }\\n-> = {\\n-  sonnet_think: (tokens: number = 1024) => ({\\n-    max_tokens: tokens * 2,\\n-    thinking: { type: 'enabled', budget_tokens: tokens } as ThinkingConfigParam,\\n-    model: 'claude-3-7-sonnet-latest'\\n-  }),\\n-  sonnet: () => ({ model: 'claude-3-7-sonnet-latest' }),\\n-  haiku: () => ({ model: 'claude3-5-haiku-latest' })\\n-}\\ndiff --git a/src/api/git.ts b/src/api/git.ts\\nindex 5d15fa6..5237b66 100644\\n--- a/src/api/git.ts\\n+++ b/src/api/git.ts\\n@@ -1,47 +1,9 @@\\n-// git diff HEAD~1 will show things like warnings and changes to .gitignore'd files\\n+import { simpleGit } from 'simple-git'\\n \\n-// git show HEAD~1 --numstat more machine readable\\n+export const getDiff = async () => {\\n+  const git = simpleGit()\\n \\n-// git diff HEAD~1 ':!package-lock.json' outputs\\n+  const diff = await git.diff()\\n \\n-/*\\n-diff --git a/package.json b/package.json\\n-index 500e658..ed3b56f 100644\\n---- a/package.json\\n-+++ b/package.json\\n-@@ -6,13 +6,15 @@\\n-   \\\"homepage\\\": \\\"https://github.com/conradbkay/llm-commit\\\",\\n-   \\\"devDependencies\\\": {\\n-     \\\"prettier\\\": \\\"^3.5.2\\\",\\n--    \\\"tsx\\\": \\\"^4.19.3\\\"\\n-+    \\\"tsx\\\": \\\"^4.19.3\\\",\\n-+    \\\"vitest\\\": \\\"^3.0.7\\\"\\n-   },\\n-   \\\"scripts\\\": {\\n-     \\\"start\\\": \\\"tsx --env-file=.env src/index.ts\\\"\\n-   },\\n-diff --git a/package.json b/package.json\\n-index 500e658..ed3b56f 100644\\n---- a/package.json\\n-+++ b/package.json\\n-@@ -6,13 +6,15 @@\\n-   \\\"homepage\\\": \\\"https://github.com/conradbkay/llm-commit\\\",\\n-   \\\"devDependencies\\\": {\\n-     \\\"prettier\\\": \\\"^3.5.2\\\",\\n--    \\\"tsx\\\": \\\"^4.19.3\\\"\\n-+    \\\"tsx\\\": \\\"^4.19.3\\\",\\n-+    \\\"vitest\\\": \\\"^3.0.7\\\"\\n-   },\\n-   \\\"scripts\\\": {\\n-     \\\"start\\\": \\\"tsx --env-file=.env src/index.ts\\\"\\n-   },\\n-   \\\"dependencies\\\": {\\n-     \\\"@anthropic-ai/sdk\\\": \\\"^0.37.0\\\",\\n--    \\\"groq-sdk\\\": \\\"^0.15.0\\\"\\n-+    \\\"groq-sdk\\\": \\\"^0.15.0\\\",\\n-+    \\\"repomix\\\": \\\"^0.2.30\\\"\\n-   }\\n- }\\n-diff --git a/prompting.md b/prompting.md\\n-index de0b3ad..61745aa 100644\\n-*/\\n+  return diff\\n+}\\ndiff --git a/src/api/groq.ts b/src/api/groq.ts\\ndeleted file mode 100644\\nindex adb6849..0000000\\n--- a/src/api/groq.ts\\n+++ /dev/null\\n@@ -1,7 +0,0 @@\\n-import Groq from 'groq-sdk'\\n-\\n-const client = new Groq({\\n-  apiKey: process.env['GROQ_API_KEY'] // This is the default and can be omitted\\n-})\\n-\\n-export const { create } = client.chat.completions\\ndiff --git a/src/index.ts b/src/index.ts\\nindex 07cfbdf..66f1d8a 100644\\n--- a/src/index.ts\\n+++ b/src/index.ts\\n@@ -1,35 +1,34 @@\\n import { writeFile } from 'fs/promises'\\n import { genPrompt } from './prompt'\\n import { unwrapResult } from '@promptbook/utils'\\n-import { configs, create } from './api/anthropic'\\n-import { readFileSync } from 'fs'\\n-import { resolve } from 'path'\\n-\\n-const diff = readFileSync(resolve('./diff.txt'), 'utf8')\\n+import { generateText } from 'ai'\\n+import { anthropic } from '@ai-sdk/anthropic'\\n+import { getDiff } from './api/git'\\n \\n const TOKENS = 1024\\n+const THINK_MODE = 'disabled'\\n \\n async function main() {\\n-  const message = await create({\\n-    max_tokens: TOKENS,\\n-    messages: [\\n-      {\\n-        role: 'user',\\n-        content: genPrompt(diff)\\n+  const model = anthropic('claude-3-7-sonnet-latest')\\n+\\n+  const diff = await getDiff()\\n+\\n+  const prompt = genPrompt(diff)\\n+\\n+  const message = await generateText({\\n+    model,\\n+    maxTokens: TOKENS,\\n+    ...prompt,\\n+    providerOptions: {\\n+      anthropic: {\\n+        thinking: { type: THINK_MODE, budgetTokens: Math.floor(TOKENS / 2) }\\n       }\\n-    ],\\n-    ...configs.sonnet_think(TOKENS)\\n+    }\\n   })\\n \\n-  if (message.content[message.content.length - 1].type !== 'text') {\\n-    throw new Error('Unexpected output length/type')\\n-  }\\n-\\n-  console.log(\\n-    unwrapResult((message.content[message.content.length - 1] as any).text)\\n-  )\\n+  console.log(unwrapResult(message.text))\\n \\n-  await writeFile('output.json', JSON.stringify(message), 'utf8')\\n+  await writeFile(model + '.json', JSON.stringify(message), 'utf8')\\n }\\n \\n main()\\ndiff --git a/src/prompt.ts b/src/prompt.ts\\nindex ca16c6f..684fa56 100644\\n--- a/src/prompt.ts\\n+++ b/src/prompt.ts\\n@@ -1,39 +1,48 @@\\n+const system =\\n+  'You are a senior software engineer working as the lead of a popular open-source project. You are presented with a code diff, and must understand the changes, then write a proper commit message for them. You will be given an example to understand what the message should look like generally'\\n+\\n // not all of these will be used. See baseDisable and custom based on model\\n const instructions = {\\n-  task: 'Your goal is to write a git commit message for a code diff',\\n-  senior:\\n-    'Reply as a senior software engineer who takes pride in their commit messages',\\n-  formatSummary:\\n-    'Always write a summary for the first line, which should be short, less than 72 characters and ideally less than 50 characters',\\n-  formatDesc:\\n-    'Any additional text is purely optional and should come after a blank line. Feel free to use bullet point format. Try not to reiterate every trivial change made to the code',\\n   logic:\\n-    \\\"Before outputting the commit, think for a few sentences about what the diffs mean, creating a list of changes. Make sure the summary generalizes to most of the changes and doesn't just focus on one. Try generating a summary, then saying whether it is general, comprehensive, and concise then trying to make a better one. Use that one in your final message rather than coming up with a separate summary\\\",\\n-  noIntro: 'Do NOT start with things like \\\"here is a commit message\\\"',\\n-  diffExplain:\\n-    'The text that follows is the code diff for the commit, your message should reflect these changes',\\n-  noHallucinate:\\n-    \\\"Be very careful not to describe any changes that weren't definitely made. It is much better to produce a very short message than make anything up\\\"\\n+    \\\"\\\\n\\\\nBefore outputting the commit, think for a few sentences about what the diffs mean, creating a list of changes. Make sure the summary generalizes to most of the changes and doesn't just focus on one. Try generating a summary, then saying whether it is general, comprehensive, and concise then trying to make a better one. Use that one in your final message rather than coming up with a separate summary. For each point, try referencing which file change(s) it correlates to\\\",\\n+  'no-hallicinate':\\n+    \\\"Be very careful not to describe any changes that weren't definitely made. It is much better to produce a very short message than make anything up\\\",\\n+  examples: `\\\\n\\\\n<example>\\n+updated code to use locally hosted ollama llm, nomic-embed-text model\\n+</example>\\n+  \\n+  <example>Update setup_mcp.py\\n+Added import platform to detect the operating system\\n+Used platform.system() to check if it's Windows or not\\n+Adjusted pip and python paths:\\n+\\n+Windows: uses 'Scripts' folder and '.exe' extension\\n+Mac/Linux: uses 'bin' folder without extension\\n+\\n+The script now automatically detects the operating system and uses the appropriate paths for each one, making it compatible with both Windows and macOS/Linux systems</example>\\n+\\n+<example>\\n+set the embedding model in an environment variable\\n+</example>`,\\n+  'think-first':\\n+    '\\\\n\\\\nPlease make sure your commit message comes after any thinking/reasoning about the code changes'\\n } as const\\n \\n-// mostly used for benchmarking/prompt development\\n+// used for benchmarking/prompt development\\n const experimentalInstructions = {\\n-  outputUsage:\\n+  'output-usage':\\n     'Your output will be fed to git commit -m \\\"[your commit message]\\\"',\\n   explanation: 'Explain why changes were made'\\n } as const\\n \\n const instructionKeyOrder = [\\n-  'task',\\n-  'senior',\\n   'explanation',\\n-  'outputUsage',\\n-  'formatSummary',\\n-  'formatDesc',\\n-  'logic',\\n-  'noIntro',\\n-  'diffExplain',\\n-  'noHallucinate'\\n+  'output-usage',\\n+  // just use a thinking model for this?\\n+  //'logic',\\n+  //'no-hallucinate',\\n+  'examples',\\n+  'think-first'\\n ] as const\\n \\n export const genPrompt = (\\n@@ -44,10 +53,20 @@ export const genPrompt = (\\n     .filter(\\n       (key) => key in instructions && !disableInstructionKeys.includes(key)\\n     )\\n-    .reduce((accum, instructionKey) => {\\n-      return accum + instructions[instructionKey] + '. '\\n-    }, '')\\n+    .map((key) => instructions[key])\\n+    .join('')\\n     .trim()\\n \\n-  return base + '\\\\n\\\\n' + diff\\n+  return {\\n+    system,\\n+    messages: [\\n+      // apparently long context (20k+) at the top performs a lot better, but can test for shorter\\n+      { role: 'user' as const, content: `<diff>${diff}</diff>\\\\n\\\\n${base}` }\\n+      // causes error for think mode\\n+      /*{\\n+        role: 'assistant' as const,\\n+        content: 'The first change to the code is'\\n+      }*/\\n+    ]\\n+  }\\n }\\n</diff>\\n\\n<example>\\nupdated code to use locally hosted ollama llm, nomic-embed-text model\\n</example>\\n  \\n  <example>Update setup_mcp.py\\nAdded import platform to detect the operating system\\nUsed platform.system() to check if it's Windows or not\\nAdjusted pip and python paths:\\n\\nWindows: uses 'Scripts' folder and '.exe' extension\\nMac/Linux: uses 'bin' folder without extension\\n\\nThe script now automatically detects the operating system and uses the appropriate paths for each one, making it compatible with both Windows and macOS/Linux systems</example>\\n\\n<example>\\nset the embedding model in an environment variable\\n</example>\\n\\nPlease make sure your commit message comes after any thinking/reasoning about the code changes\"}]}]}"},"response":{"id":"msg_01VFxH36ygfXHZTA5kYxz4At","timestamp":"2025-03-05T23:28:43.002Z","modelId":"claude-3-7-sonnet-20250219","headers":{"anthropic-organization-id":"08ef5215-d715-4f22-a8e0-171ce4bd7da4","anthropic-ratelimit-input-tokens-limit":"20000","anthropic-ratelimit-input-tokens-remaining":"15000","anthropic-ratelimit-input-tokens-reset":"2025-03-05T23:28:50Z","anthropic-ratelimit-output-tokens-limit":"8000","anthropic-ratelimit-output-tokens-remaining":"8000","anthropic-ratelimit-output-tokens-reset":"2025-03-05T23:28:44Z","anthropic-ratelimit-requests-limit":"50","anthropic-ratelimit-requests-remaining":"49","anthropic-ratelimit-requests-reset":"2025-03-05T23:28:36Z","anthropic-ratelimit-tokens-limit":"28000","anthropic-ratelimit-tokens-remaining":"23000","anthropic-ratelimit-tokens-reset":"2025-03-05T23:28:44Z","cf-cache-status":"DYNAMIC","cf-ray":"91bd63feddad3035-BOS","connection":"keep-alive","content-encoding":"gzip","content-type":"application/json","date":"Wed, 05 Mar 2025 23:28:44 GMT","request-id":"req_01Cp2xDev6FER5htHt32pJDr","server":"cloudflare","transfer-encoding":"chunked","via":"1.1 google","x-robots-tag":"none"},"messages":[{"role":"assistant","content":[{"type":"text","text":"I need to analyze this diff to understand what changes were made across the project.\n\nThe main changes appear to be:\n1. Replacing specific AI SDKs with the more general AI SDK from Vercel\n2. Removing lefthook (a git hooks manager)\n3. Updating the .gitignore to handle multiple outputs\n4. Updating dependencies in package.json\n5. Enhancing the README with more references and information\n6. Refactoring the API integration code to use the new SDK\n7. Simplifying the git diff retrieval with simple-git\n\nThe summary should capture the main theme of these changes. The most significant change is the switch from specific AI provider SDKs to the more general AI SDK framework, which enables support for multiple AI providers.\n\nLet me try a summary: \"refactor: switch to AI SDK for multi-provider support\"\n\nThis is fairly general and covers the main architectural change, but could be more specific about what providers are now supported.\n\nBetter summary: \"refactor: replace Anthropic/Groq SDKs with AI SDK for multi-provider support\"\n\nThis is more comprehensive and specific, mentioning both what was removed and what was added, while staying under 72 characters.\n\nrefactor: replace Anthropic/Groq SDKs with AI SDK for multi-provider support\n\nThe commit modernizes the project's AI integration by:\n- Replacing direct Anthropic and Groq SDKs with Vercel's AI SDK\n- Adding support for multiple AI providers (Anthropic, Deepseek, XAI)\n- Simplifying git operations with simple-git library\n- Removing lefthook git hooks manager\n- Updating .gitignore to handle multiple outputs directory\n- Enhancing README with additional references and documentation\n- Restructuring the prompt generation to work with the new SDK"}],"id":"msg-IN4H4qAMY3NqkyJ2IyjcvEdC"}]},"providerMetadata":{"anthropic":{"cacheCreationInputTokens":0,"cacheReadInputTokens":0}},"experimental_providerMetadata":{"anthropic":{"cacheCreationInputTokens":0,"cacheReadInputTokens":0}},"isContinued":false}],"experimental_providerMetadata":{"anthropic":{"cacheCreationInputTokens":0,"cacheReadInputTokens":0}},"providerMetadata":{"anthropic":{"cacheCreationInputTokens":0,"cacheReadInputTokens":0}},"sources":[]}